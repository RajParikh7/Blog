{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention is All you need\n",
    "\n",
    "download the dataset from: https://download.pytorch.org/tutorial/data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "import time,math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "UNK_token = 3\n",
    "\n",
    "class Lang:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\" , 2: \"PAD\" , 3:\"UNK\"}\n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False, filter_pair=True):\n",
    "    \n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    if filter_pair:\n",
    "        pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence, max_len ):\n",
    "    arr = [PAD_token]*max_len\n",
    "    \n",
    "    for idx,word in enumerate( sentence.split(' ') ):\n",
    "        arr[idx] = lang.word2index[word]\n",
    "        \n",
    "    arr[idx+1] = EOS_token\n",
    "    return arr\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence, max_len):\n",
    "    indexes = indexesFromSentence(lang, sentence,max_len)\n",
    "    result = torch.LongTensor(indexes)\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair, input_lang, output_lang, in_max, out_max ):\n",
    "    input_variable = variableFromSentence( input_lang, pair[0], in_max)\n",
    "    target_variable = variableFromSentence( output_lang, pair[1], out_max)\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class lang2lang( Dataset ):\n",
    "    \n",
    "    def __init__( self, pairs, input_lang, output_lang, in_max, out_max ):\n",
    "        super(lang2lang,self).__init__()\n",
    "        self.pairs = pairs\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "        self.in_max = in_max\n",
    "        self.out_max = out_max\n",
    "    \n",
    "    def __len__( self ):    \n",
    "        return len( self.pairs )\n",
    "    \n",
    "    def __getitem__( self, idx ):\n",
    "        \n",
    "        input_variable=variableFromSentence(self.input_lang, self.pairs[ idx][0], self.in_max)\n",
    "        target_variable=variableFromSentence(self.output_lang, self.pairs[ idx][1], self.out_max)\n",
    "        \n",
    "        return { \"input\":input_variable , \"target\":target_variable }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = lang2lang( pairs, input_lang, output_lang, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader( dataset,batch_size=16,shuffle=False,num_workers=4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model and sublayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Softmax3D( nn.Module ):\n",
    "    \n",
    "    def __init__( self ):\n",
    "        super( Softmax3D, self ).__init__()\n",
    "    \n",
    "    def forward( self, x ):\n",
    "        s0,s1,s2 = x.size()\n",
    "        return F.softmax( x.view(s0*s1,s2) ).view( s0,s1,s2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ScaledAttention( nn.Module ):\n",
    "    '''Scaled dot product attention mechanism basis of Attention is all you need\n",
    "       three things required query key value,\n",
    "       key and value are always same,\n",
    "       when self attention query is also the same\n",
    "       when not query is from the decoder'''\n",
    "    \n",
    "    def __init__( self, d , dropout=0.1 , n_head=1):\n",
    "        \n",
    "        super( ScaledAttention, self).__init__()\n",
    "        self.scale = np.power(d, 0.5)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.softmax = Softmax3D()\n",
    "        self.n_head = n_head\n",
    "\n",
    "    def forward( self , query , key , value , attn_mask=None ):\n",
    "        attn_val = torch.bmm( query , key.transpose(1,2) ) / self.scale\n",
    "        \n",
    "        if attn_mask is not None:\n",
    "            attn_val.data.masked_fill_( attn_mask.repeat(self.n_head,1,1) , -float('inf') )\n",
    "        \n",
    "        attn_val = self.softmax(attn_val)\n",
    "        attn_val = self.dropout(attn_val)\n",
    "        output   = torch.bmm( attn_val, value )\n",
    "        \n",
    "        return output , attn_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention( nn.Module ):\n",
    "    \n",
    "    def __init__( self , d_model, n_head , dropout=0.1):\n",
    "        super( MultiHeadAttention, self ).__init__()\n",
    "        \n",
    "        assert d_model%n_head == 0 , \"n_head({}) must divide d_model({})\".format(n_head,d_model) \n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.d_intermediate = self.d_model // self.n_head\n",
    "        \n",
    "        self.start_proj_q = nn.Linear(self.d_model, self.d_model)\n",
    "        self.start_proj_k = nn.Linear(self.d_model, self.d_model)\n",
    "        self.start_proj_v = nn.Linear(self.d_model, self.d_model)\n",
    "        \n",
    "        self.attention = ScaledAttention(self.d_intermediate, dropout, n_head)\n",
    "        \n",
    "        self.proj = nn.Linear(d_model,d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward( self , query , key , value , attn_mask=None ):\n",
    "        batch_size = query.size(0)\n",
    "        \n",
    "        query = self.start_proj_q( query )\n",
    "        key   = self.start_proj_k( key )\n",
    "        value = self.start_proj_v( value )\n",
    "        \n",
    "        query = torch.cat( query.split( self.d_intermediate,-1 ) , 0)\n",
    "        key   = torch.cat(   key.split( self.d_intermediate,-1 ) , 0)\n",
    "        value = torch.cat( value.split( self.d_intermediate,-1 ) , 0)\n",
    "        \n",
    "        output, attn = self.attention(query, key, value, attn_mask )\n",
    "        output = torch.cat( output.split( batch_size,0 ) , -1)\n",
    "        \n",
    "        output = self.proj( output )\n",
    "        output = self.dropout( output )\n",
    "        \n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward( nn.Module ):\n",
    "\n",
    "    def __init__(self, d_model, d_inner=None, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        \n",
    "        if d_inner==None:\n",
    "            d_inner = 4*d_model\n",
    "        \n",
    "        self.proj = nn.Linear(d_model, d_inner) \n",
    "        self.proj_out = nn.Linear(d_inner, d_model) \n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        output = F.relu( self.proj(x) )\n",
    "        output = self.proj_out(output)\n",
    "        output = self.dropout(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, eps=1e-3):\n",
    "        super(LayerNormalization, self).__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(d_model), requires_grad=True)\n",
    "        self.offset = nn.Parameter(torch.zeros(d_model), requires_grad=True)\n",
    "\n",
    "    def forward(self, z):\n",
    "        if z.size(1) == 1:\n",
    "            return z\n",
    "\n",
    "        mu = torch.mean(z, keepdim=True, dim=-1)\n",
    "        sigma = torch.std(z, keepdim=True, dim=-1)\n",
    "        ln_out = (z - mu.expand_as(z)) / (sigma.expand_as(z) + self.eps)\n",
    "        ln_out = ln_out * self.scale.expand_as(ln_out) + self.offset.expand_as(ln_out)\n",
    "\n",
    "        return ln_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderLayer( nn.Module ):\n",
    "    \n",
    "    def __init__( self, d_model, n_head ,dropout=0.1 ):\n",
    "        \n",
    "        super( EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention( d_model, n_head, dropout )\n",
    "        self.feedforward = PositionwiseFeedForward( d_model, dropout=dropout )\n",
    "        \n",
    "        self.layer_normalization_att = LayerNormalization(d_model)\n",
    "        self.layer_normalization_feed = LayerNormalization(d_model)\n",
    "        \n",
    "    def forward( self, enc_input, self_attn_mask=None ):\n",
    "        \n",
    "        enc_out, _ = self.attention(enc_input,enc_input,enc_input,self_attn_mask )\n",
    "        enc_out = self.layer_normalization_att( enc_out + enc_input )\n",
    "        \n",
    "        enc_out = self.layer_normalization_feed( self.feedforward(enc_out) + enc_out )\n",
    "        return enc_out , _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, n_head, dropout=0.1):\n",
    "        \n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.self_attention = MultiHeadAttention(d_model, n_head, dropout=dropout)\n",
    "        self.enc_attention = MultiHeadAttention(d_model, n_head, dropout=dropout)\n",
    "        self.feedforward = PositionwiseFeedForward(d_model, dropout=dropout)\n",
    "        \n",
    "        self.layer_normalization_self = LayerNormalization(d_model)\n",
    "        self.layer_normalization_enc  = LayerNormalization(d_model)\n",
    "        self.layer_normalization_feed = LayerNormalization(d_model)\n",
    "        \n",
    "    def forward(self, dec_input, enc_output, self_attn_mask=None, enc_attn_mask=None):\n",
    "        \n",
    "        dec_output, _ = self.self_attention(dec_input, dec_input, dec_input, attn_mask=self_attn_mask)\n",
    "        dec_input = self.layer_normalization_self( dec_input + dec_output )\n",
    "        \n",
    "        dec_output, __ = self.enc_attention(dec_input, enc_output, enc_output, attn_mask=enc_attn_mask)\n",
    "        dec_output = self.layer_normalization_enc( dec_input + dec_output )\n",
    "        \n",
    "        dec_output = self.layer_normalization_feed( self.feedforward(dec_output) + dec_output )\n",
    "\n",
    "        return dec_output, _ , __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def position_encoding_init(n_position, d_pos_vec):\n",
    "    ''' Init the sinusoid position encoding table '''\n",
    "\n",
    "    position_enc = np.array( [ [pos / np.power(10000, 2*i/d_pos_vec) for i in range(d_pos_vec)]\n",
    "                                if pos != 0 else np.zeros(d_pos_vec) \n",
    "                                for pos in range(n_position) ] )\n",
    "\n",
    "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
    "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
    "    return torch.from_numpy(position_enc).type(torch.FloatTensor)\n",
    "\n",
    "def get_attn_padding_mask(seq_q, seq_k):\n",
    "    ''' Indicate the padding-related part to mask '''\n",
    "    \n",
    "    assert seq_q.dim() == 2 and seq_k.dim() == 2\n",
    "    \n",
    "    mb_size, len_q = seq_q.size()\n",
    "    mb_size, len_k = seq_k.size()\n",
    "    \n",
    "    pad_attn_mask = seq_k.data.eq( PAD_token ).unsqueeze(1)   # bx1xsk\n",
    "    pad_attn_mask = pad_attn_mask.expand(mb_size, len_q, len_k) # bxsqxsk\n",
    "    \n",
    "    return pad_attn_mask\n",
    "\n",
    "def get_attn_subsequent_mask(seq):\n",
    "    ''' Get an attention mask to avoid using the subsequent info.'''\n",
    "    \n",
    "    assert seq.dim() == 2\n",
    "    \n",
    "    attn_shape = (seq.size(0), seq.size(1), seq.size(1))\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    subsequent_mask = torch.from_numpy(subsequent_mask)\n",
    "    \n",
    "    return subsequent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__( self, src_vocab , max_seq_len, n_layers=6, n_head=8, d_word_vec=512, d_model=512, dropout=0.1):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.position_enc = nn.Embedding( max_seq_len+1, d_word_vec )\n",
    "        self.position_enc.weight.data = position_encoding_init(max_seq_len+1, d_word_vec)\n",
    "\n",
    "        self.src_word_emb = nn.Embedding( src_vocab, d_word_vec, padding_idx=PAD_token)\n",
    "\n",
    "        self.layer = nn.ModuleList( [EncoderLayer(d_model, n_head, dropout=dropout) for _ in range(n_layers)] )\n",
    "\n",
    "    def forward(self, src_seq, src_pos):\n",
    "       \n",
    "        enc_input = self.src_word_emb(src_seq)\n",
    "        enc_input += self.position_enc(src_pos)\n",
    "        \n",
    "        enc_outputs, enc_self_attns = [], []\n",
    "        enc_output = enc_input\n",
    "        \n",
    "        self_attn_mask = get_attn_padding_mask(src_seq, src_seq)\n",
    "        \n",
    "        for enc_layer in self.layer:\n",
    "            \n",
    "            enc_output, enc_self_attn = enc_layer( enc_output, self_attn_mask=self_attn_mask)\n",
    "    \n",
    "            enc_outputs.append( enc_output )\n",
    "            enc_self_attns.append( enc_self_attn )\n",
    "\n",
    "        return enc_outputs, enc_self_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__( self, tgt_vocab, max_seq_len, n_layers=6, n_head=8, d_word_vec=512, d_model=512, dropout=0.1):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.position_enc = nn.Embedding( max_seq_len+1, d_word_vec )\n",
    "        self.position_enc.weight.data = position_encoding_init( max_seq_len+1, d_word_vec)\n",
    "\n",
    "        self.tgt_word_emb = nn.Embedding( tgt_vocab, d_word_vec, padding_idx=PAD_token )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.layer = nn.ModuleList( [ DecoderLayer(d_model, n_head, dropout=dropout) for _ in range(n_layers) ] )\n",
    "\n",
    "    def forward(self, tgt_seq, tgt_pos, src_seq, enc_outputs):\n",
    "        \n",
    "        dec_input = self.tgt_word_emb(tgt_seq)\n",
    "        dec_input += self.position_enc(tgt_pos)\n",
    "\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = [], [], []\n",
    "\n",
    "        dec_self_attn_pad_mask = get_attn_padding_mask(tgt_seq, tgt_seq)\n",
    "        dec_self_attn_sub_mask = get_attn_subsequent_mask(tgt_seq)\n",
    "        \n",
    "        dec_self_attn_mask     = torch.gt(dec_self_attn_pad_mask + dec_self_attn_sub_mask, 0)\n",
    "        dec_enc_attn_pad_mask  = get_attn_padding_mask(tgt_seq, src_seq)\n",
    "\n",
    "        dec_output = dec_input\n",
    "        \n",
    "        for dec_layer, enc_output in zip(self.layer, enc_outputs):\n",
    "            \n",
    "            dec_output, dec_self_attn, dec_enc_attn = dec_layer( dec_output, enc_output, \n",
    "                                                                 self_attn_mask = dec_self_attn_mask,\n",
    "                                                                 enc_attn_mask  = dec_enc_attn_pad_mask )\n",
    "\n",
    "            dec_outputs.append( dec_output )\n",
    "            dec_self_attns.append( dec_self_attn )\n",
    "            dec_enc_attns.append( dec_enc_attn )\n",
    "\n",
    "        return dec_outputs, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    ''' Attention is all you need '''\n",
    "\n",
    "    def __init__( self, src_vocab, tgt_vocab, max_seq_len, n_layers=6, n_head=8, d_word_vec=512, d_model=512,\n",
    "                  dropout=0.1, embs_share_weight=False):\n",
    "\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        assert d_model == d_word_vec,'To facilitate the residual connections.'\n",
    "        \n",
    "        self.encoder = Encoder( src_vocab, max_seq_len, n_layers=n_layers, n_head=n_head,\n",
    "                                d_word_vec=d_word_vec, d_model=d_model, dropout=dropout )\n",
    "        \n",
    "        self.decoder = Decoder( tgt_vocab, max_seq_len, n_layers=n_layers, n_head=n_head,\n",
    "                                d_word_vec=d_word_vec, d_model=d_model, dropout=dropout)\n",
    "        \n",
    "        self.tgt_word_proj = nn.Linear(d_model, tgt_vocab, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        if embs_share_weight:\n",
    "            assert src_vocab == tgt_vocab,\"To share word embedding,The vocabulary size of src/tgt must be same\"\n",
    "            self.encoder.src_word_emb.weight = self.decoder.tgt_word_emb.weight\n",
    "\n",
    "    def get_trainable_parameters(self):\n",
    "        ''' Avoid updating the position encoding '''\n",
    "        \n",
    "        enc_freezed_param_ids = set(map(id, self.encoder.position_enc.parameters()))\n",
    "        dec_freezed_param_ids = set(map(id, self.decoder.position_enc.parameters()))\n",
    "        freezed_param_ids = enc_freezed_param_ids | dec_freezed_param_ids\n",
    "        \n",
    "        return (p for p in self.parameters() if id(p) not in freezed_param_ids)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_seq, src_pos = src\n",
    "        tgt_seq, tgt_pos = tgt\n",
    "\n",
    "        enc_outputs, enc_slf_attns = self.encoder(src_seq, src_pos)\n",
    "        dec_outputs, dec_slf_attns, dec_enc_attns = self.decoder( tgt_seq, tgt_pos, src_seq, enc_outputs)\n",
    "        dec_output = dec_outputs[-1]\n",
    "        \n",
    "        seq_logit = self.tgt_word_proj(dec_output)\n",
    "        \n",
    "        sz = seq_logit.size()\n",
    "        log_loss = F.log_softmax( seq_logit.view(-1, seq_logit.size(2)) )\n",
    "        return log_loss.view( sz )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.75\n",
    "\n",
    "def train(input_variable, target_variable, model, optimizer, criterion, max_seq_len ):\n",
    "    \n",
    "    batch_size = input_variable.size(0)\n",
    "    \n",
    "    input_pos = Variable( torch.LongTensor( range(1,max_seq_len+1) ).view(1,-1).repeat(batch_size,1) )\n",
    "    target_pos = input_pos.clone()\n",
    "\n",
    "    optimizer.zero_grad()    \n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        teacher_forcing_target = Variable( torch.LongTensor([[SOS_token]]*batch_size ) )\n",
    "        teacher_forcing_target = torch.cat( ( teacher_forcing_target,target_variable[:,:-1]), dim=1)\n",
    "\n",
    "        output = model( (input_variable,input_pos) , (teacher_forcing_target,target_pos) )\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        output , output_generated = eval( input_variable, max_seq_len , model )\n",
    "                \n",
    "    loss = criterion( output.view(-1,output.size(2) ), target_variable.view(-1) )\n",
    "\n",
    "    _ , max_index = output.data.topk(1)\n",
    "    correct = ( max_index.view(-1) == target_variable.data.view(-1) ).sum()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.data[0] / 10 , correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(input_variable, max_seq_len, model ):\n",
    "    \n",
    "    batch_size = input_variable.size(0)\n",
    "    \n",
    "    input_pos  = Variable( torch.LongTensor( range(1,max_seq_len+1) ).view(1,-1).repeat(batch_size,1) )\n",
    "    target_pos = input_pos.clone()\n",
    "    \n",
    "    target_var = Variable( torch.LongTensor( [[PAD_token]]*batch_size ).repeat(1,max_seq_len) )\n",
    "    target_var[:,0] = SOS_token\n",
    "\n",
    "    for index in range(1,max_seq_len):\n",
    "\n",
    "        output = model( (input_variable,input_pos ), (target_var,target_pos ) )\n",
    "        correct_indices = output.topk(1)[1].squeeze(2)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            PADDING_REQ = (target_var[i,index-1].data[0]==EOS_token or target_var[i,index-1].data[0]==PAD_token)\n",
    "            target_var[i,index] = PAD_token if PADDING_REQ else correct_indices[i,index-1]  \n",
    "            \n",
    "    # we return the output to be used by the train instance\n",
    "    # and the target_var \n",
    "    target_var = output.topk(1)[1].squeeze(2)\n",
    "        \n",
    "    return output, target_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(model, max_seq_len, print_every=100, plot_every=100, learning_rate=0.01):\n",
    "\n",
    "    optimizer = optim.Adam( model.get_trainable_parameters() ,lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss(ignore_index=PAD_token)\n",
    "    \n",
    "    plot_losses = []\n",
    "    \n",
    "    for epoch in range(100):    \n",
    "        \n",
    "        print_loss_total = 0  \n",
    "        plot_loss_total = 0  \n",
    "\n",
    "        for iter,X in enumerate(dataloader):\n",
    "\n",
    "            input_variable  = Variable( X['input'] )\n",
    "            target_variable = Variable( X['target'] )\n",
    "\n",
    "            loss , correct = train(input_variable, target_variable, model, optimizer, criterion,\n",
    "                                   max_seq_len , epoch==99)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total  += loss\n",
    "            \n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                \n",
    "                if iter==0:\n",
    "                    print_loss_avg *= print_every\n",
    "                print_loss_total = 0\n",
    "                print('%d: %.4f' % ( epoch,  print_loss_avg))\n",
    "                total = target_variable.data.ne(PAD_token).sum()\n",
    "                print(\"current batch correct are: {}/{} = {:.6f}\".format(correct,total,correct/total) )\n",
    "\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / print_every\n",
    "                \n",
    "                if iter==0:\n",
    "                    plot_loss_avg *= print_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "            \n",
    "#             here training only a single batch of data \n",
    "#             because dont want to blow up my computer\n",
    "            \n",
    "#             if iter == 0:\n",
    "#                 break\n",
    "                \n",
    "    plt.plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Transformer( input_lang.n_words, output_lang.n_words, max_seq_len=10, n_layers=2, n_head=2,\n",
    "                     d_word_vec = 12, d_model = 12, dropout = 0 )\n",
    "\n",
    "trainIters(model, 10, print_every=500 ,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
