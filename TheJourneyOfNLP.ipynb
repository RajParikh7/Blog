{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tarfile\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing for memory network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_stories(lines):\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        if int(nid) == 1: story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            substory = None\n",
    "            substory = [[str(i)+\":\"]+x for i,x in enumerate(story) if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else: story.append(tokenize(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tar = tarfile.open(\"babi_tasks_1-20_v1-2.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "challenges = {\n",
    "    # QA1 with 10,000 samples\n",
    "    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt',\n",
    "    # QA2 with 10,000 samples\n",
    "    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt',\n",
    "    'two_supporting_facts_1k': 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt',\n",
    "}\n",
    "# challenge_type = 'single_supporting_fact_10k'\n",
    "\n",
    "challenge_type = 'two_supporting_facts_1k'\n",
    "\n",
    "challenge = challenges[challenge_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stories(f):\n",
    "    data = parse_stories(f.readlines())\n",
    "    return [(story, q, answer) for story, q, answer in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "test_stories = get_stories(tar.extractfile(challenge.format('test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_stories[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stories = train_stories + test_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "story_maxlen = max((len(s) for x, _, _ in stories for s in x))\n",
    "story_maxsents = max((len(x) for x, _, _ in stories))\n",
    "query_maxlen = max(len(x) for _, x, _ in stories)\n",
    "\n",
    "story_maxlen , story_maxsents , query_maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_flatten(el): \n",
    "    return isinstance(el, collections.Iterable) and not isinstance(el, (str, bytes))\n",
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if do_flatten(el): yield from flatten(el)\n",
    "        else: yield el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = sorted(set(flatten(stories)))\n",
    "vocab.insert(0, '<PAD>')\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "story_maxsents, vocab_size, story_maxlen, query_maxlen, len(train_stories), len(test_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_stories[534][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_idx = dict((c, i) for i, c in enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
    "    X = []; Xq = []; Y = []\n",
    "    for story, query, answer in data:\n",
    "        x = [[word_idx[w] for w in s] for s in story]\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        y = [word_idx[answer]]\n",
    "        X.append(x); Xq.append(xq); Y.append(y)\n",
    "    return ([tf.contrib.keras.preprocessing.sequence.pad_sequences(x, maxlen=story_maxlen) for x in X],\n",
    "            tf.contrib.keras.preprocessing.sequence.pad_sequences(Xq, maxlen=query_maxlen), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories, \n",
    "     word_idx, story_maxlen, query_maxlen)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories, \n",
    "     word_idx, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stack_inputs(inputs):\n",
    "    for i,it in enumerate(inputs):\n",
    "        inputs[i] = np.concatenate([it, np.zeros((story_maxsents-it.shape[0],story_maxlen), 'int')])\n",
    "    return np.stack(inputs)\n",
    "inputs_train = stack_inputs(inputs_train)\n",
    "inputs_test = stack_inputs(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_train.shape, inputs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( queries_train.shape)\n",
    "\n",
    "queries_train = queries_train[:,np.newaxis,:]\n",
    "queries_test = queries_test[:,np.newaxis,:]\n",
    "\n",
    "queries_train.shape , queries_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers_train = answers_train.reshape( (-1) )\n",
    "answers_test = answers_test.reshape( (-1) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Hop model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "story = tf.placeholder( tf.int64 , shape = [None,10,8] )\n",
    "quest = tf.placeholder( tf.int64 , shape = [None,1,4] )\n",
    "answer = tf.placeholder( tf.int64 , shape = [None] )\n",
    "is_training = tf.placeholder( tf.bool , shape = [] )\n",
    "\n",
    "emb_mat = tf.get_variable( \"emb_mat\" , shape=[vocab_size,20] , dtype=tf.float32  )\n",
    "emb_mat_2 = tf.get_variable( \"emb_mat_2\" , shape=[vocab_size,20] , dtype=tf.float32 )\n",
    "\n",
    "z = tf.nn.embedding_lookup( emb_mat , story )\n",
    "sent_emb1 = tf.reduce_sum( z, axis=2)\n",
    "\n",
    "y = tf.nn.embedding_lookup( emb_mat , quest )\n",
    "quest_emb = tf.reduce_sum( y, axis=2)\n",
    "\n",
    "u = tf.matmul( sent_emb1 , quest_emb ,transpose_b=True)\n",
    "weights = tf.nn.softmax(u,dim=1)\n",
    "\n",
    "zz = tf.nn.embedding_lookup( emb_mat_2 , story )\n",
    "\n",
    "score = tf.reduce_sum( weights * sent_emb2 , axis = 1)\n",
    "score = tf.expand_dims( score , axis = 1) + quest_emb\n",
    "score = tf.squeeze(score , axis=1 )\n",
    "\n",
    "ans = tf.layers.dense( score , vocab_size )\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(  tf.one_hot(answer,vocab_size) , ans )\n",
    "\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "correct_indices = tf.argmax( ans , axis = 1)\n",
    "correct = tf.reduce_sum( tf.cast( tf.equal( correct_indices , answer ) , dtype=tf.float32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(q1,q2,q3,session,l,t,c,saver,file=\"my_model\",batch_size=64,epoch=5):\n",
    "    \n",
    "    train_indices = np.arange( q1.shape[0] )\n",
    "    np.random.shuffle( train_indices )\n",
    "    \n",
    "    for e in tqdm_notebook( range(epoch) ,leave=False):\n",
    "        \n",
    "        correct = 0\n",
    "        losses = []\n",
    "        for cc in tqdm_notebook( range(int(math.ceil(q1.shape[0]/batch_size))) ,leave=False):\n",
    "            \n",
    "            start_idx = (cc*batch_size)%q1.shape[0]\n",
    "            idx = train_indices[ start_idx : start_idx+batch_size]\n",
    "            \n",
    "            feed_dict = { story : q1[idx] , quest : q2[idx] , answer : q3[idx] , is_training: True } \n",
    "            actual_batch_size = q1[idx].shape[0]\n",
    "            \n",
    "            lr, corr, _ = session.run( [l,c,t] , feed_dict=feed_dict )\n",
    "            \n",
    "            losses.append(lr*actual_batch_size)\n",
    "            correct += corr\n",
    "        \n",
    "        if saver != None:\n",
    "            path = \"tmp/\" + file\n",
    "            saver.save(sess , path , global_step = e)\n",
    "        \n",
    "        total_correct = correct/q1.shape[0]\n",
    "        total_loss = np.sum(losses)/q1.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\".format(total_loss,total_correct,e+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver() \n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "#     for i in range(10):\n",
    "#         q,w,za = sess.run([weights,correct,train_op],feed_dict={ story:inputs_train[:5],quest:queries_train[:5],answer:answers_train[:5] })\n",
    "#         print(q)\n",
    "#         print(w)\n",
    "#     saver.restore(sess,\"tmp/nlp1-4\")\n",
    "    run_model(inputs_train,queries_train,answers_train,sess,loss,train_op,correct,saver,file=\"nlp1\",batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi hop\n",
    "##### change the challenge type to 'two supporting facts 1k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_train.shape, inputs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queries_train.shape , answers_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(2)\n",
    "\n",
    "story = tf.placeholder( tf.int64 , shape = [None,88,8] )\n",
    "quest = tf.placeholder( tf.int64 , shape = [None,1,5] )\n",
    "answer = tf.placeholder( tf.int64 , shape = [None] )\n",
    "is_training = tf.placeholder( tf.bool , shape = [] )\n",
    "\n",
    "with tf.variable_scope(\"emb\"):\n",
    "    emb_mat_A = tf.get_variable( \"emb_mat_A\" , shape=[vocab_size,30] )\n",
    "    emb_mat_C = tf.get_variable( \"emb_mat_C\" , shape=[vocab_size,30] )\n",
    "    \n",
    "z = tf.nn.embedding_lookup( emb_mat_A , story )\n",
    "sent_emb_A = tf.reduce_sum( z, axis=2)\n",
    "\n",
    "z = tf.nn.embedding_lookup( emb_mat_C , story )\n",
    "sent_emb_C = tf.reduce_sum( z, axis=2)\n",
    "\n",
    "z = tf.nn.embedding_lookup( emb_mat_A , quest )\n",
    "quest_emb = tf.reduce_sum( z, axis=2)\n",
    "\n",
    "num_supporting_facts = 2\n",
    "\n",
    "# A_i = A , for all i\n",
    "# C_i = C , for all i\n",
    "\n",
    "for c in range( num_supporting_facts ):\n",
    "    \n",
    "    weights = tf.matmul( sent_emb_A , quest_emb , transpose_b=True)\n",
    "    softmax_weights = tf.nn.softmax( weights, dim=1)\n",
    "\n",
    "    o = tf.reduce_sum( softmax_weights * sent_emb_C,axis=1 , keep_dims=True) \n",
    "\n",
    "    check = None if c==0 else True\n",
    "    quest_emb = tf.expand_dims( tf.layers.dense(tf.squeeze(quest_emb,axis=1),30,name=\"H\",reuse=check),axis=1 )+o\n",
    "    \n",
    "ans = tf.layers.dense( tf.squeeze( quest_emb , axis =1) , vocab_size )\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(  tf.one_hot(answer,vocab_size) , ans )\n",
    "train_op = tf.train.RMSPropOptimizer(0.005).minimize(loss)\n",
    "\n",
    "correct_indices = tf.argmax( ans , axis = 1)\n",
    "correct = tf.reduce_sum( tf.cast( tf.equal( correct_indices , answer ) , dtype=tf.float32 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver() \n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "#     for i in range(50):\n",
    "#         q,w = sess.run([correct,train_op],feed_dict={ story:inputs_train[:100],quest:queries_train[:100],answer:answers_train[:100] })\n",
    "#         print(q)\n",
    "#     saver.restore(sess,\"tmp/nlp_self_paper-19\")\n",
    "    for loop in range(3):\n",
    "        run_model(inputs_train,queries_train,answers_train,sess,loss,train_op,correct,saver,file=\"nlp2\",batch_size=32,epoch=10)\n",
    "        print(\"validation:--\")\n",
    "        run_model(inputs_test,queries_test,answers_test,sess,loss,loss,correct,saver=None,batch_size=32,epoch=1)\n",
    "\n",
    "#     run_model(inputs_train,queries_train,answers_train,sess,loss,train_op,correct,saver,file=\"nlp_self_paper\",batch_size=32,epoch=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spelling Bee CMU preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('A', ['AH0']), ('ZYWICKI', ['Z', 'IH0', 'W', 'IH1', 'K', 'IY0']))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = [l.strip().split(\"  \") for l in open(\"cmudict-0.7b\", encoding='latin1') \n",
    "         if re.match('^[A-Z]', l)]\n",
    "lines = [(w, ps.split()) for w, ps in lines]\n",
    "lines[0], lines[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_', 'AA0', 'AA1', 'AA2', 'AE0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes = [\"_\"] + sorted(set(p for w, ps in lines for p in ps))\n",
    "phonemes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p2i = dict((v, k) for k,v in enumerate(phonemes))\n",
    "letters = \"_abcdefghijklmnopqrstuvwxyz*\"\n",
    "l2i = dict((v, k) for k,v in enumerate(letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108006"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen=15\n",
    "pronounce_dict = {w.lower(): [p2i[p] for p in ps] for w, ps in lines if (5<=len(w)<=maxlen) and re.match(\"^[A-Z]+$\", w)}\n",
    "len(pronounce_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen_p = max([len(v) for k,v in pronounce_dict.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maxlen is the length of words and maxlen_p is the lenght of the phenotic sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen_p , maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = np.random.permutation(list(pronounce_dict.keys()))\n",
    "n = len(pairs)\n",
    "input_ = np.zeros((n, maxlen_p), np.int32)\n",
    "labels_ = np.zeros((n, maxlen), np.int32)\n",
    "\n",
    "for i, k in enumerate(pairs):\n",
    "    for j, p in enumerate(pronounce_dict[k]): input_[i][j] = p\n",
    "    for j, letter in enumerate(k): labels_[i][j] = l2i[letter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "go_token = l2i[\"*\"]\n",
    "dec_input_ = np.concatenate([np.ones((n,1)) * go_token, labels_[:,:-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(input_train, input_test, labels_train, labels_test, dec_input_train, dec_input_test\n",
    "    ) = train_test_split(input_, labels_, dec_input_, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97205, 16), (97205, 15))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape , labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97205, 15), (97205, 15))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_input_train.shape , labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab_size, output_vocab_size = len(phonemes), len(letters)\n",
    "input_vocab_size, output_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without teacher forcing\n",
    "https://www.quora.com/What-is-the-teacher-forcing-in-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ff3bab3b4a2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder( tf.int64 , shape=[None,16] )\n",
    "Y = tf.placeholder( tf.int64 , shape=[None,15] )\n",
    "\n",
    "emb_mat = tf.get_variable( \"emb_mat\" , shape=[input_vocab_size,120] )\n",
    "\n",
    "emb_x = tf.nn.embedding_lookup( emb_mat , X )\n",
    "\n",
    "emb_x_time_major = tf.transpose( emb_x , [1,0,2])\n",
    "\n",
    "cell_fw = tf.contrib.rnn.BasicLSTMCell(dim)\n",
    "cell_bw = tf.contrib.rnn.BasicLSTMCell(dim)\n",
    "\n",
    "bi_rnn_out , bi_rnn_state = tf.nn.bidirectional_dynamic_rnn( cell_fw , cell_bw , emb_x_time_major , \n",
    "                                                            time_major=True, dtype=tf.float32)\n",
    "bi_rnn_out = tf.concat(bi_rnn_out, 2)\n",
    "\n",
    "cell_second_layer = tf.contrib.rnn.BasicLSTMCell(dim)\n",
    "rnn_out , rnn_state = tf.nn.dynamic_rnn(cell_second_layer , bi_rnn_out,\n",
    "                                        time_major=True, dtype=tf.float32)\n",
    "rnn_out_last = rnn_out[-1]\n",
    "\n",
    "# decoder input is just the final context vector * num of outputs ( maxlen )\n",
    "# here we should ideally concatenate the context vector at each time step\n",
    "# to the output of the previous timestep answer\n",
    "# intially it can be the start token concatenated with the context vector\n",
    "# but its quite inconvinent to write such code in TF ( if not impossible )\n",
    "\n",
    "repeat_rnn_last = tf.stack( [rnn_out_last]*maxlen , axis=1 )\n",
    "\n",
    "last_cells = tf.contrib.rnn.BasicLSTMCell(dim)\n",
    "\n",
    "final_out , final_out_state = tf.nn.dynamic_rnn( last_cells ,  repeat_rnn_last , dtype=tf.float32 , scope=\"rnn2\")\n",
    "\n",
    "result = tf.layers.dense( final_out , output_vocab_size )\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(  tf.one_hot( Y,output_vocab_size ) , result )\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "correct_indices = tf.argmax( result , axis = 2 )\n",
    "correct = tf.reduce_sum( tf.cast( tf.equal( correct_indices , Y ) , dtype=tf.float32 ) ) / maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(q1,q2,q3,session,l,t,c,saver,file=\"my_model\",batch_size=64,epoch=5):\n",
    "    \n",
    "    train_indices = np.arange( q1.shape[0] )\n",
    "#     np.random.shuffle( train_indices )\n",
    "    \n",
    "    for e in tqdm_notebook( range(epoch) ,leave=False):\n",
    "        \n",
    "        correct = 0\n",
    "        losses = []\n",
    "        for cc in tqdm_notebook( range(int(math.ceil(q1.shape[0]/batch_size))) ,leave=False):\n",
    "            \n",
    "            start_idx = (cc*batch_size)%q1.shape[0]\n",
    "            idx = train_indices[ start_idx : start_idx+batch_size]\n",
    "            \n",
    "            feed_dict = { X : q1[idx] , Y : q2[idx] , X_y : q3[idx] , seq_len : [15]*len(idx) } \n",
    "            actual_batch_size = q1[idx].shape[0]\n",
    "            \n",
    "            lr, corr, _ = session.run( [l,c,t] , feed_dict=feed_dict )\n",
    "            \n",
    "            losses.append(lr*actual_batch_size)\n",
    "            correct += corr\n",
    "        \n",
    "        if saver != None:\n",
    "            path = \"tmp/\" + file\n",
    "            saver.save(sess , path , global_step = e)\n",
    "        \n",
    "        total_correct = correct/q1.shape[0]\n",
    "        total_loss = np.sum(losses)/q1.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\".format(total_loss,total_correct,e+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver() \n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    run_model(input_test,labels_test,sess,loss,train_op,correct,saver,file=\"nlp_pro\",batch_size=512,epoch=1)\n",
    "    \n",
    "#     saver.restore(sess,\"tmp/nlp_pro-3\")\n",
    "#     for i in range(10):\n",
    "#     q = sess.run( correct_indices ,feed_dict={ X:input_train[:1000],Y:labels_train[:1000] })\n",
    "#     print( np.sum( np.sum( np.equal(q,labels_train[:1000] ) ,axis=1) == 15) )\n",
    "\n",
    "#     print( ''.join( [letters[i] for i in a] ) , ''.join( [letters[i] for i in b] ) )\n",
    "#         print(q,w)\n",
    "        \n",
    "#     saver.restore(sess,\"tmp/nlp_pro-3\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to understand the encoder decoder model is to first study \n",
    "\n",
    "# Neural Machine Translation by Jointly Learning to Align and Translate\n",
    "https://arxiv.org/abs/1409.0473\n",
    "# Chris manning's nlp course\n",
    "https://www.youtube.com/watch?v=IxQtK2SjWWM&list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6&index=11\n",
    "# and by far the best video i have ever come across, my hero Quoc V le\n",
    "https://www.youtube.com/watch?v=G5RY_SUJih4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# also it would be wonder ful to study just the readme of NMT implemented by google, i have later almost replicated there work in a neat way which makes it much easier to understand\n",
    "\n",
    "https://github.com/tensorflow/nmt/blob/master/README.md\n",
    "\n",
    "but it would be best if could yourself experiment with why creating two sperate graphs is better as opposed to messing all things up in one,\n",
    "# one point to convince yourself why we are able to save from one graph and load in another is , by printing the trainable variables in both the case , and observing that both are identical so its correct to load it in a later graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder( tf.int32 , shape=[None,16] )\n",
    "X_y = tf.placeholder( tf.int32 , shape=[None,15] )\n",
    "seq_len = tf.placeholder( tf.int32 , shape=[None] )\n",
    "\n",
    "Y = tf.placeholder( tf.int32 , shape=[None,15] )\n",
    "\n",
    "emb_mat = tf.get_variable( \"emb_mat\" , shape=[input_vocab_size,120] )\n",
    "emb_out = tf.get_variable( \"emb_out\" , shape=[output_vocab_size,120] )\n",
    "\n",
    "emb_x = tf.nn.embedding_lookup( emb_mat , X )\n",
    "emb_x_y = tf.nn.embedding_lookup( emb_out , X_y )\n",
    "\n",
    "with tf.name_scope(\"Encoder\"):\n",
    "    cell_fw = tf.contrib.rnn.BasicLSTMCell(dim)\n",
    "    cell_bw = tf.contrib.rnn.BasicLSTMCell(dim)\n",
    "\n",
    "    enc_rnn_out , enc_rnn_state = tf.nn.bidirectional_dynamic_rnn( cell_fw , cell_bw , emb_x , dtype=tf.float32)\n",
    "    enc_rnn_out = tf.concat(enc_rnn_out, 2)\n",
    "\n",
    "    c = tf.concat([enc_rnn_state[0][0],enc_rnn_state[1][0]],axis=1)\n",
    "    h = tf.concat([enc_rnn_state[0][1],enc_rnn_state[1][1]],axis=1)\n",
    "\n",
    "    enc_rnn_state = tf.contrib.rnn.LSTMStateTuple(c,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Decoder\"):\n",
    "    \n",
    "    mem_units = 2*dim\n",
    "    dec_cell = tf.contrib.rnn.BasicLSTMCell( 2*dim )\n",
    "\n",
    "    attn_mech = tf.contrib.seq2seq.BahdanauAttention( num_units = mem_units,  memory = enc_rnn_out, normalize=True)\n",
    "    attn_cell = tf.contrib.seq2seq.AttentionWrapper( cell = dec_cell,attention_mechanism = attn_mech ) \n",
    "\n",
    "    batch_size = tf.shape(enc_rnn_out)[0]\n",
    "    initial_state = attn_cell.zero_state( batch_size = batch_size , dtype=tf.float32 )\n",
    "    initial_state = initial_state.clone(cell_state = enc_rnn_state)\n",
    "\n",
    "    out_layer = Dense( output_vocab_size )\n",
    "    \n",
    "    with tf.variable_scope(\"Training\"):\n",
    "    \n",
    "        helper = tf.contrib.seq2seq.TrainingHelper( inputs = emb_x_y , sequence_length = seq_len )\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder( cell = attn_cell, helper = helper, initial_state = initial_state ,output_layer=out_layer ) \n",
    "        outputs, final_state, final_sequence_lengths= tf.contrib.seq2seq.dynamic_decode(decoder=decoder,impute_finished=True)\n",
    "\n",
    "        training_logits = tf.identity(outputs.rnn_output )\n",
    "        training_pred = tf.identity(outputs.sample_id )\n",
    "    \n",
    "    with tf.variable_scope(\"Inference\"):\n",
    "        \n",
    "        start_tokens = tf.tile(tf.constant([27], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "        end_token = 0\n",
    "        \n",
    "        inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(emb_out,start_tokens, end_token)\n",
    "        inference_decoder = tf.contrib.seq2seq.BasicDecoder(attn_cell,inference_helper,initial_state, out_layer)\n",
    "        inference_out,_,__ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,impute_finished=True,maximum_iterations=maxlen)\n",
    "        \n",
    "        inference_logits = inference_out.rnn_output \n",
    "        inference_pred = inference_out.sample_id \n",
    "        \n",
    "with tf.name_scope(\"Training_op\"):\n",
    "    \n",
    "    loss = tf.losses.softmax_cross_entropy(  tf.one_hot( Y,output_vocab_size ) , training_logits )\n",
    "    train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "    correct = tf.reduce_sum( tf.cast( tf.equal( training_pred , Y ) , dtype=tf.float32 ) ) / maxlen\n",
    "\n",
    "with tf.name_scope(\"Inference_op\"):\n",
    "    \n",
    "    correct_inference = tf.reduce_sum( tf.cast( tf.equal( inference_pred , Y ), dtype=tf.float32 ) ) / maxlen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'emb_mat:0' shape=(70, 120) dtype=float32_ref>\n",
      "<tf.Variable 'emb_out:0' shape=(28, 120) dtype=float32_ref>\n",
      "<tf.Variable 'bidirectional_rnn/fw/basic_lstm_cell/kernel:0' shape=(131, 44) dtype=float32_ref>\n",
      "<tf.Variable 'bidirectional_rnn/fw/basic_lstm_cell/bias:0' shape=(44,) dtype=float32_ref>\n",
      "<tf.Variable 'bidirectional_rnn/bw/basic_lstm_cell/kernel:0' shape=(131, 44) dtype=float32_ref>\n",
      "<tf.Variable 'bidirectional_rnn/bw/basic_lstm_cell/bias:0' shape=(44,) dtype=float32_ref>\n",
      "<tf.Variable 'memory_layer/kernel:0' shape=(22, 22) dtype=float32_ref>\n",
      "<tf.Variable 'Training/decoder/attention_wrapper/basic_lstm_cell/kernel:0' shape=(164, 88) dtype=float32_ref>\n",
      "<tf.Variable 'Training/decoder/attention_wrapper/basic_lstm_cell/bias:0' shape=(88,) dtype=float32_ref>\n",
      "<tf.Variable 'Training/decoder/attention_wrapper/bahdanau_attention/query_layer/kernel:0' shape=(22, 22) dtype=float32_ref>\n",
      "<tf.Variable 'Training/decoder/attention_wrapper/bahdanau_attention/attention_v:0' shape=(22,) dtype=float32_ref>\n",
      "<tf.Variable 'Training/decoder/attention_wrapper/bahdanau_attention/attention_g:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'Training/decoder/attention_wrapper/bahdanau_attention/attention_b:0' shape=(22,) dtype=float32_ref>\n",
      "<tf.Variable 'Training/decoder/dense/kernel:0' shape=(22, 28) dtype=float32_ref>\n",
      "<tf.Variable 'Training/decoder/dense/bias:0' shape=(28,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "for i in tf.get_collection(\"trainable_variables\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf830b780f244ed79bafb3baf278cb11"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a66504f20a4f27bdcd0ff9878acfdd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Overall loss = 3.33 and accuracy of 0.016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dffc7eb5824fb19e1fe91f647cff7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Overall loss = 3.29 and accuracy of 0.133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5fb86cb83646499fb9c65ff1234b3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Overall loss = 3.25 and accuracy of 0.471\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd5669583c94d16950009af8dfb41bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Overall loss = 3.21 and accuracy of 0.476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc8c989b1be45029e967ce2b4058d45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Overall loss = 3.17 and accuracy of 0.476\n",
      "\r"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "#     saver.restore(sess,'tmp/nlp_seq2seq_final-0')\n",
    "    run_model( input_train,labels_train,dec_input_train,sess,loss,train_op,correct,saver,file=\"nlp_sof\")\n",
    "#     q,w = sess.run( [correct_inference,inference_pred] ,feed_dict={ X:input_test[:1000],Y:labels_test[:1000] })\n",
    "#     print(q)\n",
    "#     print( np.sum( np.sum( np.equal(w,labels_test[:1000] ) ,axis=1) == 15) )\n",
    "#     print(w[:10])\n",
    "#     print( ''.join( [letters[i] for i in a] ) , ''.join( [letters[i] for i in b] ) )\n",
    "#     print(q,w)\n",
    "        \n",
    "    \n",
    "#     for i in range(100):\n",
    "#         feed_dict = { X:input_train[:10] , X_y:dec_input_train[:10] , Y:labels_train[:10] , seq_len:[15]*10 }\n",
    "#         q,_,__ = sess.run([loss,correct,train_op] , feed_dict=feed_dict )\n",
    "#         print( q,_ )\n",
    "#         if i==99:\n",
    "#             print( sess.run( [training_pred] , feed_dict=feed_dict ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22,  5, 18,  9, 20, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [23,  9, 12,  9, 19, 20,  1, 14,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [19, 21, 20, 20,  4, 15, 15, 14,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [12,  1,  3, 20, 20, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  5, 12,  3, 14,  5, 18,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  9,  9,  3, 14,  9,  1, 14, 19,  0,  0,  0,  0,  0,  0],\n",
       "       [ 6, 15, 13,  9, 14, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [12,  1,  2, 18,  5,  3, 11,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 2,  1, 14,  7, 15, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 7,  5, 18, 19, 20,  9, 14, 14,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "veritt_________ verit__________ False\n",
      "wilistan_______ williston______ False\n",
      "suttdoon_______ southdown______ False\n",
      "lacttr_________ lacter_________ False\n",
      "celcner________ kelchner_______ False\n",
      "ciicnians______ chechnyans_____ False\n",
      "fominn_________ foaming________ False\n",
      "labreck________ labrecque______ False\n",
      "bangoo_________ bongo__________ False\n",
      "gerstinn_______ gerstein_______ False\n",
      "geaaroo________ geoffroy_______ False\n",
      "lahhi__________ layhee_________ False\n",
      "swadd__________ swayed_________ False\n",
      "tinnn__________ tingen_________ False\n",
      "pilts__________ piltz__________ False\n",
      "vanalstinn_____ vanalstine_____ False\n",
      "aamarck________ avmark_________ False\n",
      "garder_________ gaarder________ False\n",
      "sferical_______ spherical______ False\n",
      "palppttting____ palpitating____ False\n",
      "menn___________ menia__________ False\n",
      "prlaactan______ prolactin______ False\n",
      "storms_________ stormes________ False\n",
      "sider__________ sidor__________ False\n",
      "mmprttntlly____ importantly____ False\n",
      "bottnatt_______ boitnott_______ False\n",
      "plattinn_______ plaything______ False\n",
      "valensea_______ valenza________ False\n",
      "flemans________ flemons________ False\n",
      "vinacr_________ vinocur________ False\n",
      "wrhthlin_______ wirthlin_______ False\n",
      "restlaslly_____ restlessly_____ False\n",
      "prapoond_______ propound_______ False\n",
      "wundrdd________ wondered_______ False\n",
      "seneress_______ sceneries______ False\n",
      "wemblly________ wembley________ False\n",
      "wicatt_________ wicat__________ False\n",
      "beleem_________ belem__________ False\n",
      "felbatal_______ felbatol_______ False\n",
      "dinatec________ dynatech_______ False\n",
      "nussrr_________ nusser_________ False\n",
      "sinii__________ zinni__________ False\n",
      "aneett_________ anette_________ False\n",
      "antuann________ antoine________ False\n",
      "hantt__________ hanta__________ False\n",
      "hargraa________ hargrave_______ False\n",
      "leett__________ leith__________ False\n",
      "sulli__________ sully__________ False\n",
      "disids_________ decides________ False\n",
      "sednteeeei_____ sedentary______ False\n",
      "ruball_________ wrubel_________ False\n",
      "crcconbrggg____ kruckenberg____ False\n",
      "ploff__________ plouff_________ False\n",
      "caller_________ collier________ False\n",
      "ppstnatll______ postnatal______ False\n",
      "heberal________ haeberle_______ False\n",
      "cernan_________ keranen________ False\n",
      "dinodd_________ denude_________ False\n",
      "celsan_________ kelson_________ False\n",
      "pecien_________ pecina_________ False\n",
      "pollee_________ pauli__________ False\n",
      "dadria_________ deandrea_______ False\n",
      "sccratic_______ socratic_______ False\n",
      "wolls__________ walles_________ False\n",
      "frutiggr_______ frutiger_______ False\n",
      "stubei_________ stubby_________ False\n",
      "wilbancs_______ willbanks______ False\n",
      "habbrl_________ haberl_________ False\n",
      "beicinn________ beaching_______ False\n",
      "ilnas__________ illness________ False\n",
      "renaaater______ renovator______ False\n",
      "lanctree_______ lanktree_______ False\n",
      "hhorpponing____ sharpening_____ False\n",
      "copin__________ coppin_________ False\n",
      "rrestrants_____ registrants____ False\n",
      "maconvill______ mcconville_____ False\n",
      "renn___________ renna__________ False\n",
      "apinn__________ aping__________ False\n",
      "tecampp________ teakamp________ False\n",
      "smeliing_______ smelling_______ False\n",
      "insiser________ incisor________ False\n",
      "nicii__________ nickey_________ False\n",
      "frewillinn_____ freewheeling___ False\n",
      "dimeglioo______ dimeglio_______ False\n",
      "acstman________ axtman_________ False\n",
      "navereet_______ navarrette_____ False\n",
      "siricc_________ syrek__________ False\n",
      "garttr_________ garter_________ False\n",
      "cinser_________ kinzer_________ False\n",
      "crttaffrssnn___ christofferson_ False\n",
      "apalggatt______ applegate______ False\n",
      "scoldid________ scalded________ False\n",
      "viseblly_______ visibly________ False\n",
      "dalafilld______ dalafield______ False\n",
      "sessrr_________ caesar_________ False\n",
      "nttrgeccsin____ interjection___ False\n",
      "natddrft_______ nothdurft______ False\n",
      "reaampinn______ revamping______ False\n",
      "gadfliss_______ gadflies_______ False\n",
      "manaab_________ mcnab__________ False\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip( w[:100] , labels_test[:100] ):\n",
    "    k,l = ''.join( [letters[i] for i in a] ) , ''.join( [letters[i] for i in b] ) \n",
    "    print(  k,l,k==l )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# clever way to implement two seperate graphs with the same trainable variables\n",
    "\n",
    "the thing in which i got stuck for  a long time was , for beam search decoding we are suppose to tile the encoder outputs and states beam with times , we are not supposed to do so with the start token , this is really confusing and lacks consistency and clarity , the wrapper functions should themselves do the tiling for the encoder outputs and states , because of this i was stuck and assumed wrongly that the variables for attention would be different which wasnt the case and as someone pointed in the github issue i had posted i was able to see the mistake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# tensorflow / nmt replicated in a simple way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### greedy decoding and beam search with beam width one is equivalent\n",
    "\n",
    "obvious pointers , which is not so obvious for most of us\n",
    "\n",
    "beam search only makes sense in the time of inference\n",
    "using bi directional lstm in the decoder side doesnt make sense to me\n",
    "##### for decoder we can make initial state as the encoder final state but that doesnt improve performance as mentioned by chris manning is the cs 224n in lecture 10 , so most of the figures shown for seq2seq model are misleading\n",
    "eg , \n",
    "https://github.com/tensorflow/nmt/blob/master/nmt/g3doc/img/seq2seq.jpg\n",
    "### its better you see the models as,\n",
    "https://syncedreview.com/2017/07/11/massive-exploration-of-neural-machine-translation-architectures/\n",
    "\n",
    "https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_placeholders():\n",
    "    X = tf.placeholder( tf.int32 , shape=[None,16] )\n",
    "    X_y = tf.placeholder( tf.int32 , shape=[None,15] )\n",
    "    seq_len = tf.placeholder( tf.int32 , shape=[None] )\n",
    "\n",
    "    Y = tf.placeholder( tf.int32 , shape=[None,15] )\n",
    "    \n",
    "    return ( X , Y , X_y , seq_len )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _decoder( encoder_outputs , encoder_state ,source_sequence_length , batch_size , mode , beam_width ):\n",
    "    \n",
    "    num_units = 2*dim\n",
    "    memory = encoder_outputs\n",
    "\n",
    "    if mode == \"infer\":\n",
    "        memory = tf.contrib.seq2seq.tile_batch( memory, multiplier=beam_width )\n",
    "        source_sequence_length = tf.contrib.seq2seq.tile_batch( source_sequence_length, multiplier=beam_width)\n",
    "        encoder_state = tf.contrib.seq2seq.tile_batch( encoder_state, multiplier=beam_width )\n",
    "        batch_size = batch_size * beam_width\n",
    "    else:\n",
    "        batch_size = batch_size\n",
    "\n",
    "    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention( num_units = num_units, memory=memory, \n",
    "                                                               normalize=True,\n",
    "                                                               memory_sequence_length=source_sequence_length)\n",
    "\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell( 2*dim )\n",
    "\n",
    "    cell = tf.contrib.seq2seq.AttentionWrapper( cell,\n",
    "                                                attention_mechanism,\n",
    "                                                attention_layer_size=num_units,\n",
    "                                                name=\"attention\")\n",
    "\n",
    "    decoder_initial_state = cell.zero_state(batch_size, tf.float32).clone( cell_state=encoder_state )\n",
    "\n",
    "    return cell, decoder_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Decoder( mode , enc_rnn_out , enc_rnn_state , seq_len ,emb_x_y , emb_out):\n",
    "    \n",
    "    with tf.variable_scope(\"Decoder\") as decoder_scope:\n",
    "\n",
    "        mem_units = 2*dim\n",
    "        out_layer = Dense( output_vocab_size )\n",
    "        batch_size = tf.shape(enc_rnn_out)[0]\n",
    "        beam_width = 3\n",
    "\n",
    "        cell , initial_state = _decoder( enc_rnn_out ,enc_rnn_state , seq_len , batch_size , mode , beam_width )\n",
    "\n",
    "        if mode == \"train\":\n",
    "\n",
    "            helper = tf.contrib.seq2seq.TrainingHelper( inputs = emb_x_y , sequence_length = seq_len )\n",
    "            decoder = tf.contrib.seq2seq.BasicDecoder( cell = cell, helper = helper, initial_state = initial_state,output_layer=out_layer) \n",
    "            outputs, final_state, final_sequence_lengths= tf.contrib.seq2seq.dynamic_decode(decoder=decoder,\n",
    "                                                                                        maximum_iterations=maxlen,\n",
    "                                                                                           scope=decoder_scope)\n",
    "\n",
    "            logits = outputs.rnn_output\n",
    "            sample_ids = outputs.sample_id\n",
    "\n",
    "        else:\n",
    "\n",
    "            start_tokens = tf.tile(tf.constant([27], dtype=tf.int32), [ batch_size ] )\n",
    "            end_token = 0\n",
    "\n",
    "            my_decoder = tf.contrib.seq2seq.BeamSearchDecoder( cell = cell,\n",
    "                                                               embedding = emb_out,\n",
    "                                                               start_tokens = start_tokens,\n",
    "                                                               end_token = end_token,\n",
    "                                                               initial_state = initial_state,\n",
    "                                                               beam_width = beam_width,\n",
    "                                                               output_layer = out_layer )\n",
    "\n",
    "            outputs, t1 , t2 = tf.contrib.seq2seq.dynamic_decode(  my_decoder,\n",
    "                                                                   maximum_iterations=maxlen,scope=decoder_scope )\n",
    "\n",
    "            logits = tf.no_op()\n",
    "            sample_ids = outputs.predicted_ids\n",
    "        \n",
    "    return logits , sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_graph(mode,inp):\n",
    "\n",
    "    X , Y , X_y , seq_len = inp\n",
    "    \n",
    "    emb_mat = tf.get_variable( \"emb_mat\" , shape=[input_vocab_size,120] )\n",
    "    emb_out = tf.get_variable( \"emb_out\" , shape=[output_vocab_size,120] )\n",
    "\n",
    "    emb_x = tf.nn.embedding_lookup( emb_mat , X )\n",
    "    emb_x_y = tf.nn.embedding_lookup( emb_out , X_y )\n",
    "\n",
    "    with tf.name_scope(\"Encoder\"):\n",
    "        cell_fw = tf.contrib.rnn.BasicLSTMCell(dim)\n",
    "        cell_bw = tf.contrib.rnn.BasicLSTMCell(dim)\n",
    "\n",
    "        enc_rnn_out , enc_rnn_state = tf.nn.bidirectional_dynamic_rnn( cell_fw , cell_bw , emb_x , dtype=tf.float32)\n",
    "        enc_rnn_out = tf.concat(enc_rnn_out, 2)\n",
    "\n",
    "        c = tf.concat([enc_rnn_state[0][0],enc_rnn_state[1][0]],axis=1)\n",
    "        h = tf.concat([enc_rnn_state[0][1],enc_rnn_state[1][1]],axis=1)\n",
    "\n",
    "        enc_rnn_state = tf.contrib.rnn.LSTMStateTuple(c,h)\n",
    "\n",
    "    logits , sample_ids = Decoder(mode, enc_rnn_out , enc_rnn_state , seq_len , emb_x_y, emb_out)\n",
    "    \n",
    "    if mode == \"train\":\n",
    "\n",
    "        loss = tf.losses.softmax_cross_entropy(  tf.one_hot( Y,output_vocab_size ) , logits )\n",
    "        train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "        correct = tf.reduce_sum( tf.cast( tf.equal( sample_ids , Y ) , dtype=tf.float32 ) ) / maxlen\n",
    "    else:\n",
    "#         sample_ids = tf.transpose( sample_ids , [2,0,1] )[0]\n",
    "        correct = None\n",
    "#         correct = tf.reduce_sum( tf.cast( tf.equal( sample_ids , Y ) , dtype=tf.float32 ) ) / maxlen\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        \n",
    "    return train_op , loss , correct , sample_ids , logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(inp,q1,q2,q3,session,l,t,c,saver,file=\"my_model\",batch_size=64,epoch=5):\n",
    "    \n",
    "    train_indices = np.arange( q1.shape[0] )\n",
    "    \n",
    "    for e in tqdm_notebook( range(epoch) ,leave=False):\n",
    "        \n",
    "        correct = 0\n",
    "        losses = []\n",
    "        for cc in tqdm_notebook( range(int(math.ceil(q1.shape[0]/batch_size))) ,leave=False):\n",
    "            \n",
    "            start_idx = (cc*batch_size)%q1.shape[0]\n",
    "            idx = train_indices[ start_idx : start_idx+batch_size]\n",
    "            \n",
    "            feed_dict = { inp[0]: q1[idx] , inp[1]: q2[idx] , inp[2]: q3[idx] , inp[3]: [15]*len(idx) } \n",
    "            actual_batch_size = q1[idx].shape[0]\n",
    "            \n",
    "            lr, corr, _ = session.run( [l,c,t] , feed_dict=feed_dict )\n",
    "            \n",
    "            losses.append(lr*actual_batch_size)\n",
    "            correct += corr\n",
    "        \n",
    "        if saver != None:\n",
    "            path = \"tmp/\" + file\n",
    "            saver.save(session , path , global_step = e)\n",
    "        \n",
    "        total_correct = correct/q1.shape[0]\n",
    "        total_loss = np.sum(losses)/q1.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\".format(total_loss,total_correct,e+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4165f70937247f38fe2bb076a78dc83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef8a5b090754ca4846b00091d72a499"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Overall loss = 1.11 and accuracy of 0.683\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb8a09780ab44c684b547ca2a8ea1b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Overall loss = 0.463 and accuracy of 0.864\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4921079de7a64c408f25ecd953f2de8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Overall loss = 0.34 and accuracy of 0.896\n",
      "\r",
      "INFO:tensorflow:Restoring parameters from tmp/nlp_nmt-2\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "infer_graph = tf.Graph()\n",
    "\n",
    "with train_graph.as_default():\n",
    "    \n",
    "    train_input = get_placeholders()\n",
    "    train_op, loss , correct,sample_ids,logits = construct_graph(\"train\",train_input)\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    train_saver = tf.train.Saver()\n",
    "    \n",
    "with infer_graph.as_default():\n",
    "    \n",
    "    infer_input = get_placeholders()\n",
    "    _ , _ , correct_test , pred_ids,_ = construct_graph(\"infer\",infer_input)\n",
    "    infer_saver = tf.train.Saver()\n",
    "    \n",
    "train_sess = tf.Session(graph=train_graph)\n",
    "infer_sess = tf.Session(graph=infer_graph)\n",
    "\n",
    "train_sess.run(initializer)\n",
    "\n",
    "# for i in range(100):\n",
    "#     q,w,e,r,__ = train_sess.run( [train_op,loss,correct,sample_ids,logits],feed_dict={ train_input[0]:input_test[:10],train_input[1]:labels_test[:10],train_input[2]:dec_input_test[:10],train_input[3]:[15]*10 })\n",
    "#     print(q,w,e)\n",
    "#     print(r)\n",
    "#     print(__.shape)\n",
    "\n",
    "run_model( train_input,input_train,labels_train,dec_input_train,train_sess,loss,train_op,correct,train_saver,file=\"nlp_nmt\",epoch=3)\n",
    "\n",
    "infer_saver.restore(infer_sess, \"tmp/nlp_nmt-2\" )\n",
    "q = infer_sess.run( pred_ids,feed_dict={ infer_input[0]:input_test[:100],infer_input[1]:labels_test[:100],infer_input[2]:dec_input_test[:100],infer_input[3]:[15]*100 })\n",
    "# print(q)\n",
    "# print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 12,  5, 13,  5, 19,  8,  0, -1, -1, -1, -1, -1, -1],\n",
       "       [26,  9,  9, 18,  9, 14, 19,  0, -1, -1, -1, -1, -1, -1],\n",
       "       [21, 14,  4,  5, 18, 11, 15,  5, 20,  0, -1, -1, -1, -1],\n",
       "       [ 1, 12,  2, 21, 13,  0, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [ 5,  7, 26, 21, 12, 20,  5,  4,  0, -1, -1, -1, -1, -1],\n",
       "       [14, 15, 21, 20, 18,  1, 20,  9, 22,  5,  0, -1, -1, -1],\n",
       "       [ 2,  5,  9,  3, 15, 14, 15, 18,  0, -1, -1, -1, -1, -1],\n",
       "       [19,  8, 15,  1,  2,  0, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [11, 15, 14,  6, 15, 18, 13,  0, -1, -1, -1, -1, -1, -1],\n",
       "       [13,  9, 14, 14,  9, 22,  1, 14,  0, -1, -1, -1, -1, -1]], dtype=int32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.transpose( q,(2,0,1) )\n",
    "z[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blemish_****** blemish________\n",
      "ziirans_****** zaireans_______\n",
      "undercote_**** undercoat______\n",
      "albam_******** album__________\n",
      "exulted_****** exulted________\n",
      "nutrative_**** nutritive______\n",
      "bichonor_***** baikonur_______\n",
      "shoba_******** shobe__________\n",
      "conform_****** conform________\n",
      "minivan_****** minivan________\n",
      "troiano_****** troiano________\n",
      "munic_******** munich_________\n",
      "saliont_****** salient________\n",
      "jalif_******** jolliff________\n",
      "padolski_***** podolsky_______\n",
      "pablisity_**** publicity______\n",
      "garfield_***** garfield_______\n",
      "padle_******** paddle_________\n",
      "goberstin_**** goberstein_____\n",
      "churchous_**** churchhouse____\n",
      "pichan_******* pichon_________\n",
      "marmer_******* marmor_________\n",
      "indistinked_** indistinct_____\n",
      "bottomfish_*** bottomfish_____\n",
      "meramontes_*** miramontes_____\n",
      "taveras_****** taveras________\n",
      "astentatious_* ostentatious___\n",
      "steage_******* steege_________\n",
      "zipphal_****** zipfel_________\n",
      "show_********* schow__________\n",
      "sudennas_***** suddenness_____\n",
      "barkes_******* barkus_________\n",
      "furino_******* furino_________\n",
      "ozeck_******** ozick__________\n",
      "cargig_******* carrigg________\n",
      "plaigerism_*** plagiarism_____\n",
      "bertoni_****** bertoni________\n",
      "bunks_******** bunks__________\n",
      "machell_****** mckeel_________\n",
      "hagemier_***** hagemeyer______\n",
      "certaker_***** caretaker______\n",
      "selgeck_****** seljuk_________\n",
      "stacout_****** stakeout_______\n",
      "predomonated_* predominated___\n",
      "supersenters_* supercenters___\n",
      "panderd_****** pandered_______\n",
      "pwentes_****** puentes________\n",
      "polacoff_***** polakoff_______\n",
      "casked_******* cascade________\n",
      "boeser_******* boser__________\n",
      "credetable_*** creditable_____\n",
      "walshlager_*** wollschlager___\n",
      "dermas_******* dearmas________\n",
      "diithermy_**** diathermy______\n",
      "mertans_****** mertens________\n",
      "redneck_****** redneck________\n",
      "fedeck_******* fedak__________\n",
      "madragle_***** madrigal_______\n",
      "slavin_******* slavin_________\n",
      "soota_******** sowata_________\n",
      "inalastic_**** inelastic______\n",
      "ubink_******** ewbank_________\n",
      "consert_****** concert________\n",
      "crapples_***** krapels________\n",
      "dilly_******** dilly__________\n",
      "therm_******** therm__________\n",
      "masaru__****** masaru_________\n",
      "worships_***** warships_______\n",
      "eckter_******* ector__________\n",
      "kosts_******** coasts_________\n",
      "brack_******** braque_________\n",
      "pusher_******* pusher_________\n",
      "avontek_****** avantek________\n",
      "prinsipley_*** principally____\n",
      "bragan_******* bragan_________\n",
      "stamana_****** stamina________\n",
      "inskep_******* inskip_________\n",
      "moinihan_***** moynihan_______\n",
      "blatchy_****** blotchy________\n",
      "lianhart_***** lionheart______\n",
      "arcana_******* arcana_________\n",
      "ersola_******* ursola_________\n",
      "hardliners_*** hardliners_____\n",
      "dwiggins_***** dwiggins_______\n",
      "lithagrafic_** lithographic___\n",
      "lotton_******* laughton_______\n",
      "weach_******** wiech__________\n",
      "taho_********* tahoe__________\n",
      "erferes_****** airfares_______\n",
      "blaimed_****** blamed_________\n",
      "penman_******* penman_________\n",
      "boorsouse_**** bourgeoisie____\n",
      "rovindran_**** ravindran______\n",
      "primrous_***** primrose_______\n",
      "stalinism_**** stalinism______\n",
      "hean_********* hayne__________\n",
      "prenn_******** prenn__________\n",
      "songerath_**** sondgeroth_____\n",
      "macenry_****** masonry________\n",
      "soplant_****** supplant_______\n",
      "blemesh_****** blemish________\n",
      "ziirins_****** zaireans_______\n",
      "underkoet_**** undercoat______\n",
      "album_******** album__________\n",
      "egzulted_***** exulted________\n",
      "noutrative_*** nutritive______\n",
      "beiconor_***** baikonur_______\n",
      "shoab_******** shobe__________\n",
      "konform_****** conform________\n",
      "minnivan_***** minivan________\n",
      "troiono_****** troiano________\n",
      "munik_******** munich_________\n",
      "sailiont_***** salient________\n",
      "jolif_******** jolliff________\n",
      "podolski_***** podolsky_______\n",
      "pabliseti_**** publicity______\n",
      "gorfield_***** garfield_______\n",
      "padel_******** paddle_________\n",
      "goberstine_*** goberstein_____\n",
      "churchuus_**** churchhouse____\n",
      "pichon_******* pichon_________\n",
      "mormer_******* marmor_________\n",
      "indistinct_*** indistinct_____\n",
      "bottomfis_**** bottomfish_____\n",
      "miramontes_*** miramontes_____\n",
      "taveraus_***** taveras________\n",
      "astentatios_** ostentatious___\n",
      "stige_******** steege_________\n",
      "zipfel_******* zipfel_________\n",
      "shough_******* schow__________\n",
      "sudinnas_***** suddenness_____\n",
      "barcus_******* barkus_________\n",
      "fourino_****** furino_________\n",
      "ozek_********* ozick__________\n",
      "carrig_******* carrigg________\n",
      "plagerism_**** plagiarism_____\n",
      "bertone_****** bertoni________\n",
      "buncks_******* bunks__________\n",
      "machil_******* mckeel_________\n",
      "hagemiar_***** hagemeyer______\n",
      "certacher_**** caretaker______\n",
      "selgic_******* seljuk_________\n",
      "stacuat_****** stakeout_______\n",
      "predomanated_* predominated___\n",
      "supersentors_* supercenters___\n",
      "pandered_***** pandered_______\n",
      "puentes_****** puentes________\n",
      "polakoff_***** polakoff_______\n",
      "cascad_******* cascade________\n",
      "boser_******** boser__________\n",
      "creditable_*** creditable_____\n",
      "wolshlager_*** wollschlager___\n",
      "durmas_******* dearmas________\n",
      "diiathermy_*** diathermy______\n",
      "murtans_****** mertens________\n",
      "reedneck_***** redneck________\n",
      "fedack_******* fedak__________\n",
      "madragal_***** madrigal_______\n",
      "slaven_******* slavin_________\n",
      "soata_******** sowata_________\n",
      "inelastic_**** inelastic______\n",
      "ubenk_******** ewbank_________\n",
      "concert_****** concert________\n",
      "crapels_****** krapels________\n",
      "dilley_******* dilly__________\n",
      "thirm_******** therm__________\n",
      "masaru_******* masaru_________\n",
      "warships_***** warships_______\n",
      "ecter_******** ector__________\n",
      "costs_******** coasts_________\n",
      "brak_********* braque_________\n",
      "pousher_****** pusher_________\n",
      "avonteck_***** avantek________\n",
      "prinseply_**** principally____\n",
      "braigan_****** bragan_________\n",
      "stamona_****** stamina________\n",
      "inskip_******* inskip_________\n",
      "moinian_****** moynihan_______\n",
      "blatchi_****** blotchy________\n",
      "liinhart_***** lionheart______\n",
      "arkana_******* arcana_________\n",
      "arsola_******* ursola_________\n",
      "hordliners_*** hardliners_____\n",
      "duiggins_***** dwiggins_______\n",
      "lithografic_** lithographic___\n",
      "lotten_******* laughton_______\n",
      "weech_******** wiech__________\n",
      "tahwo_******** tahoe__________\n",
      "earferes_***** airfares_______\n",
      "blaced_******* blamed_________\n",
      "penmon_******* penman_________\n",
      "boorsousee_*** bourgeoisie____\n",
      "rovindron_**** ravindran______\n",
      "primroes_***** primrose_______\n",
      "stallinism_*** stalinism______\n",
      "hain_********* hayne__________\n",
      "pren_********* prenn__________\n",
      "songeroth_**** sondgeroth_____\n",
      "masunry_****** masonry________\n",
      "saplant_****** supplant_______\n",
      "bleemish_***** blemish________\n",
      "zeyerans_***** zaireans_______\n",
      "underkote_**** undercoat______\n",
      "albem_******** album__________\n",
      "eczulted_***** exulted________\n",
      "nutertive_**** nutritive______\n",
      "bichonore_**** baikonur_______\n",
      "schoba_******* shobe__________\n",
      "canform_****** conform________\n",
      "minevan_****** minivan________\n",
      "troyano_****** troiano________\n",
      "munick_******* munich_________\n",
      "saliant_****** salient________\n",
      "jaliff_******* jolliff________\n",
      "padolsky_***** podolsky_______\n",
      "pablisety_**** publicity______\n",
      "garfeild_***** garfield_______\n",
      "paddle_******* paddle_________\n",
      "gooberstin_*** goberstein_____\n",
      "cherchuus_**** churchhouse____\n",
      "pichen_******* pichon_________\n",
      "marmar_******* marmor_________\n",
      "indistingt_*** indistinct_____\n",
      "bottemfish_*** bottomfish_____\n",
      "mearamontes_** miramontes_____\n",
      "taveraz_****** taveras________\n",
      "ostentatious_* ostentatious___\n",
      "steege_******* steege_________\n",
      "zipfal_******* zipfel_________\n",
      "shaw_********* schow__________\n",
      "sudennass_**** suddenness_____\n",
      "barcas_******* barkus_________\n",
      "fureno_******* furino_________\n",
      "ozick_******** ozick__________\n",
      "kargig_******* carrigg________\n",
      "plaigerizom_** plagiarism_____\n",
      "bertony_****** bertoni________\n",
      "bunkes_******* bunks__________\n",
      "mckell_******* mckeel_________\n",
      "haggimiar_**** hagemeyer______\n",
      "certacer_***** caretaker______\n",
      "selgack_****** seljuk_________\n",
      "stachout_***** stakeout_______\n",
      "predamonated_* predominated___\n",
      "soopersentors_ supercenters___\n",
      "pandord_****** pandered_______\n",
      "pwentess_***** puentes________\n",
      "policoff_***** polakoff_______\n",
      "cascade_****** cascade________\n",
      "bouser_******* boser__________\n",
      "credatable_*** creditable_____\n",
      "walshleger_*** wollschlager___\n",
      "dermes_******* dearmas________\n",
      "diiathormy_*** diathermy______\n",
      "mertuns_****** mertens________\n",
      "redeneck_***** redneck________\n",
      "fedick_******* fedak__________\n",
      "madregal_***** madrigal_______\n",
      "clavin_******* slavin_________\n",
      "soote_******** sowata_________\n",
      "inalastec_**** inelastic______\n",
      "ubank_******** ewbank_________\n",
      "konsert_****** concert________\n",
      "krapels_****** krapels________\n",
      "dilli_******** dilly__________\n",
      "therme_******* therm__________\n",
      "masarou_****** masaru_________\n",
      "worsheps_***** warships_______\n",
      "echter_******* ector__________\n",
      "cousts_******* coasts_________\n",
      "brakk_******** braque_________\n",
      "poosher_****** pusher_________\n",
      "avontec_****** avantek________\n",
      "prinsiply_**** principally____\n",
      "braigon_****** bragan_________\n",
      "stamena_****** stamina________\n",
      "inckep_******* inskip_________\n",
      "moiniahn_***** moynihan_______\n",
      "blatchey_***** blotchy________\n",
      "leinhart_***** lionheart______\n",
      "arkanna_****** arcana_________\n",
      "orsola_******* ursola_________\n",
      "hardlinars_*** hardliners_____\n",
      "duiggens_***** dwiggins_______\n",
      "lithagrafik_** lithographic___\n",
      "lottun_******* laughton_______\n",
      "weich_******** wiech__________\n",
      "tahho_******** tahoe__________\n",
      "eerferes_***** airfares_______\n",
      "blaemed_****** blamed_________\n",
      "penmen_******* penman_________\n",
      "boorsoasee_*** bourgeoisie____\n",
      "rovinderne_*** ravindran______\n",
      "primros_****** primrose_______\n",
      "stallinizom_** stalinism______\n",
      "heen_********* hayne__________\n",
      "pren__******** prenn__________\n",
      "songerahth_*** sondgeroth_____\n",
      "masenry_****** masonry________\n",
      "suplant_****** supplant_______\n"
     ]
    }
   ],
   "source": [
    "for cc in range(3):\n",
    "    for a,b in zip(z[cc],labels_test[:100]):\n",
    "        print( ''.join( [letters[i] for i in a] ) , ''.join( [letters[i] for i in b] ) )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## english is a hard language to read and say there is much differnce i suspect these results would be brilliantly better for my mother tongue Hindi / Nepali :p "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
